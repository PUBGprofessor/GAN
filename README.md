## 版本v1:

1. 数据集同时使用MNIST数据集和G.gteImage(),每次根据索引取出一张，然后由datasetloader每次取batchsize次，G.forward()无法并行，导致取数据漫

2. G全卷积层，初始随机传入一个大的x数组，可能占内存大
3. 损失函数使用均方误差
4. D和G训练比1：200

训练过慢，无法实用

## 版本v2：

1. 数据集只用MNIST，batch下取数据快
2. G两层全连接＋一层卷积
3. 使用手写的交叉熵损失
4. D和G训练比 1：300

训练速度还好，D损失下降快，训练充分；G训练不出来，输出的随机图片

## 版本v3.0：

总结问题：

1. D 收敛得太快，直接就把 G 生成的图片看穿了，D最后一层的激活函数为sigmod，训练太好导致每次返回（在sigmod的左右两侧）梯度消失
2. 让 D **不要太自信**，反而有助于 G 的训练

解决：

1. 减少D的网络层数，增加G网络层数，使用假标签（**真实标签为 1** 的地方改成 **0.9**，**假标签 0** 改为 **0.1**），防止sigmod梯度消失
2. 加入假标签，减慢训练D的能力
3. D和G训练比 1：10

G训练失败，输出无规律

## 版本v3.1：

1. lossG使用 BCEWithLogitsLoss 计算损失
2. D和G训练比 1：30

G训练失败，输出无规律

## 版本v3.2：

1. lossG和lossD使用 BCEloss计算损失
2. D和G训练比 1：1
3. 加入标签交换

G训练失败，输出无规律

## 版本v3.2_

1. D和G训练比 1：5
2. 增加很多优化器参数：optim.Adam(G.parameters(), 1e-4, betas=(0.5, 0.999), weight_decay=1e-4)

3. 标签交换：交换率逐渐下降，超过epoch/2后不交换

有了一些稍微能看的输出：

![image-20250413112541920](C:\Users\刘佳豪\AppData\Roaming\Typora\typora-user-images\image-20250413112541920.png)

但后面还是不行

### 版本v4.0

1. 训练比1：1
2. 改写G的网络，加入nn.LeakyReLU和dropout

## 版本v4.1

1. 改写D的网络，加入dropout

### 版本v5.0

1. 使用其他人的G和D模型
2. 训练比1：1